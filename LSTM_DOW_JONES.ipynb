{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c9236b72-b645-4695-9c8c-222bf5c326b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import RECH_functions as RECH\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "14a12cb2-f514-4059-8d8a-b5f757d9abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_func = RECH.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e5dd1fa3-c2b2-44a5-8680-245a4a81ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [\"MMM\",\n",
    "\"AXP\",\n",
    "\"AMGN\",\n",
    "\"AAPL\",\n",
    "\"BA\",\n",
    "\"CAT\",\n",
    "\"CVX\",\n",
    "\"CSCO\",\n",
    "\"KO\",\n",
    "\"DOW\",\n",
    "\"GS\",\n",
    "\"HD\",\n",
    "\"HON\",\n",
    "\"INTC\",\n",
    "\"IBM\",\n",
    "\"JNJ\",\n",
    "\"JPM\",\n",
    "\"MCD\",\n",
    "\"MRK\",\n",
    "\"MSFT\",\n",
    "\"NKE\",\n",
    "\"PG\",\n",
    "\"CRM\",\n",
    "\"TRV\",\n",
    "\"UNH\",\n",
    "\"VZ\",\n",
    "\"V\",\n",
    "\"WBA\",\n",
    "\"WMT\",\n",
    "\"DIS\",\n",
    "\"^GSPC\"]\n",
    "my_list.remove(\"DOW\") # dow joined in 2019\n",
    "my_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1b68534c-f903-4d0d-8442-29cdba6c3a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_list = [\"IBM\", \"AAPL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2b2607c7-99dc-4afa-b187-db2b36c95398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_list = [\"PG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d73db82a-67c4-4b21-8f14-085c656cbbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "####################\n",
      "Date\n",
      "2012-01-04 00:00:00-05:00   -0.044893\n",
      "2012-01-05 00:00:00-05:00   -0.420073\n",
      "2012-01-06 00:00:00-05:00   -0.240788\n",
      "2012-01-09 00:00:00-05:00    0.421052\n",
      "Name: log_ret * 100, dtype: float64\n",
      "####################\n",
      "Index(['PG_1_h_sigma', 'PG_1_h_omega', 'PG_2_h_sigma', 'PG_2_h_omega'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#forecasts_symbol = pd.DataFrame(index=os_data.index) # empty dataframe to be filles with forecasts of different horizons\n",
    "change_par = 0.2\n",
    "\n",
    "vP0 = (0.1, 0.8, 0.1, 0.1 , 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1)\n",
    "my_bounds = ((0.0001,1), (0.0001,1), (0.0001, 10),  (0.0001, 3) , (-10, 10), (-10, 10), (-10, 10), (-10,10), (-10, 10) , (-10, 10), (-10,10), (-10, 10) , (-10, 10), (-10,10), (-10, 10) , (-10, 10), (-100,100), (-100,100), (-100,100), (-100,100))\n",
    "\n",
    "par_names = [\"alpha\", \"beta\", \"gamma_0\", \"gamma_1\", \"v_11\", \"v_12\", \"v_21\", \"v_22\", \"v_31\", \"v_32\", \"v_41\", \"v_42\", \"w_1\", \"w_2\", \"w_3\", \"w_4\", \"b_c\", \"b_o\", \"b_i\", \"b_f\"]\n",
    "\n",
    "forecast_all = pd.DataFrame()\n",
    "\n",
    "def con(t):\n",
    "    return (-1)*(t[0] + t[1]) + 0.99\n",
    "cons = {'type':'ineq', 'fun': con}\n",
    "\n",
    "df_pars = pd.DataFrame(columns = par_names, index = my_list)\n",
    "mc_M = 5000\n",
    "\n",
    "act_func = RECH.relu\n",
    "warning_list = []\n",
    "for symbol in my_list:\n",
    "    pd_this_share = \n",
    "    is_list = [(pd_this_share.index[x] < datetime.date(2017, 1, 1)) for x in range(len(pd_this_share)) ]\n",
    "    is_data = pd_this_share[is_list]\n",
    "    is_data.drop(index=is_data.index[0], axis=0, inplace=True) # dropping the first value with NA in returns\n",
    "    is_returns = is_data['log_ret * 100']\n",
    "    print(\"####################\")\n",
    "    print(is_returns.head(4))\n",
    "    print(\"####################\")\n",
    "    # out of sample data is all the data from 01.01.2015\n",
    "    os_list = [(pd_this_share.index[x] >= datetime.date(2017, 1, 1)) for x in range(len(pd_this_share)) ]\n",
    "    os_data = pd_this_share[os_list]\n",
    "    os_returns = os_data['log_ret * 100']\n",
    "    vP0 = (0.1, 0.8, 0.1, 0.1 , 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1)\n",
    "    my_bounds = ((0.0001,1), (0.0001,1), (0.0001, 10),  (0.0001, 3) , (-10, 10), (-10, 10), (-10, 10), (-10,10), (-10, 10) , (-10, 10), (-10,10), (-10, 10) , (-10, 10), (-10,10), (-10, 10) , (-10, 10), (-100,100), (-100,100), (-100,100), (-100,100))\n",
    "    \n",
    "    update_window = 20 # length of the updating window 20 -> monthly, 5 -> weekly\n",
    "    sample_returns = is_returns # the sample returns serires keeps getting longer: after each iteration new informatuion is added\n",
    "    os_decreasing = os_returns # out of sample returns, shrinking as sample increases\n",
    "    forecasts_symbol = pd.DataFrame(index=os_data.index)\n",
    "    horizons = (1, 5, 20)\n",
    "    for p in range(len(horizons)):\n",
    "        forecasts_symbol[symbol + f\"_{horizons[p]}_h_sigma\"] = np.zeros(len(os_returns))\n",
    "        forecasts_symbol[symbol + f\"_{horizons[p]}_h_omega\"] = np.zeros(len(os_returns))\n",
    "    #print(symbol + f\"_{horizons[p]}_h\")\n",
    "    print(forecasts_symbol.columns)\n",
    "\n",
    "    for i in range(int(len(os_returns)/update_window)):\n",
    "        if i == 0:\n",
    "            # different starting values for optimisation as well as for forecasting in the first iteration\n",
    "            res_lstm = opt.minimize(RECH.LSTM_garch_loglike, vP0, args = (act_func, sample_returns),\n",
    "                          bounds = my_bounds,\n",
    "                           #method = \"Nelder-Mead\",\n",
    "                            method = \"SLSQP\",\n",
    "                          options = {\"disp\": False, \"maxiter\": 100000, \"ftol\": 0.1},\n",
    "                           constraints = cons)\n",
    "            # sample returns contain all information up to t = t\n",
    "            # mc forecast function uses the lastest return as information\n",
    "            \n",
    "            for k in range(update_window):\n",
    "                \"\"\"for every time (t+1), (t+2), ... there are 3 forecasts made with respective information\n",
    "                (t+1)-h1, (t+1)-h2, (t+1)-h3, (t+2)-h1, ... \"\"\"\n",
    "                for horizon in horizons:\n",
    "                    fore_sigma = RECH.mc_lstm2(res_lstm.x, act_func, sample_returns[:-horizon], mc_M, horizon)[0]\n",
    "                    fore_omega = RECH.mc_lstm2(res_lstm.x, act_func, sample_returns[:-horizon], mc_M, horizon)[1]\n",
    "                    forecasts_symbol[symbol + f\"_{horizon}_h_sigma\"].iloc[i*update_window + k] = fore_sigma\n",
    "                    forecasts_symbol[symbol + f\"_{horizon}_h_omega\"].iloc[i*update_window + k] = fore_omega\n",
    "                    if fore_sig < 0:\n",
    "                        warning_list.append(symbol)\n",
    "                        warning_list.append(res_srn.x)\n",
    "                ### now for every k the sample grows by 1\n",
    "                sample_returns = sample_returns.append(os_decreasing.head(1))\n",
    "                os_decreasing = os_decreasing.tail(-1)\n",
    "                \n",
    "        else:\n",
    "            sample_returns = sample_returns.tail(-update_window)\n",
    "            new_bounds = my_bounds\n",
    "            res_lstm = opt.minimize(RECH.LSTM_garch_loglike, res_lstm.x, args = (act_func, sample_returns),\n",
    "                          bounds = new_bounds,\n",
    "                           #method = \"Nelder-Mead\",\n",
    "                            method = \"SLSQP\",\n",
    "                          options = {\"disp\": False, \"maxiter\": 30000, \"ftol\": 0.1},\n",
    "                            constraints = cons)\n",
    "            for k in range(update_window):\n",
    "                \"\"\"for every time (t+1), (t+2), ... there are 3 forecasts made with respective information\n",
    "                (t+1)-h1, (t+1)-h2, (t+1)-h3, (t+2)-h1, ... \"\"\"\n",
    "                for horizon in horizons:\n",
    "                    fore_sigma = RECH.mc_lstm2(res_lstm.x, act_func, sample_returns[:-horizon], mc_M, horizon)[0]\n",
    "                    fore_omega = RECH.mc_lstm2(res_lstm.x, act_func, sample_returns[:-horizon], mc_M, horizon)[1]\n",
    "                    forecasts_symbol[symbol + f\"_{horizon}_h_sigma\"].iloc[i*update_window + k] = fore_sigma\n",
    "                    forecasts_symbol[symbol + f\"_{horizon}_h_omega\"].iloc[i*update_window + k] = fore_omega\n",
    "                    if fore_sig < 0:\n",
    "                        warning_list.append(symbol)\n",
    "                        warning_list.append(res_srn.x)\n",
    "                ### now for every k the sample grows by 1\n",
    "                sample_returns = sample_returns.append(os_decreasing.head(1))\n",
    "                os_decreasing = os_decreasing.tail(-1)\n",
    "                #print(f\"in sample: {len(sample_returns)}, out of sample: {len(os_decreasing)}\")\n",
    "    forecast_all = pd.concat([forecast_all, forecasts_symbol], axis=1)\n",
    "    df_pars.iloc[my_list.index(symbol)] = res_lstm.x  \n",
    "with open('lstm_warnings', 'wb') as fp:\n",
    "    pickle.dump(warning_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "66b02936-5bdc-4070-8945-bd2108cf4123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PG_1_h_sigma</th>\n",
       "      <th>PG_1_h_omega</th>\n",
       "      <th>PG_2_h_sigma</th>\n",
       "      <th>PG_2_h_omega</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03 00:00:00-05:00</th>\n",
       "      <td>0.646467</td>\n",
       "      <td>0.285623</td>\n",
       "      <td>0.464847</td>\n",
       "      <td>0.307302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04 00:00:00-05:00</th>\n",
       "      <td>0.608758</td>\n",
       "      <td>0.237918</td>\n",
       "      <td>1.665656</td>\n",
       "      <td>0.654365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05 00:00:00-05:00</th>\n",
       "      <td>0.595918</td>\n",
       "      <td>0.246900</td>\n",
       "      <td>0.826666</td>\n",
       "      <td>0.967940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06 00:00:00-05:00</th>\n",
       "      <td>0.560800</td>\n",
       "      <td>0.231005</td>\n",
       "      <td>2.076522</td>\n",
       "      <td>0.359668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09 00:00:00-05:00</th>\n",
       "      <td>0.540207</td>\n",
       "      <td>0.213986</td>\n",
       "      <td>0.475901</td>\n",
       "      <td>2.597965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-25 00:00:00-04:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-26 00:00:00-04:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-27 00:00:00-04:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-28 00:00:00-04:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-29 00:00:00-04:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           PG_1_h_sigma  PG_1_h_omega  PG_2_h_sigma  \\\n",
       "Date                                                                  \n",
       "2017-01-03 00:00:00-05:00      0.646467      0.285623      0.464847   \n",
       "2017-01-04 00:00:00-05:00      0.608758      0.237918      1.665656   \n",
       "2017-01-05 00:00:00-05:00      0.595918      0.246900      0.826666   \n",
       "2017-01-06 00:00:00-05:00      0.560800      0.231005      2.076522   \n",
       "2017-01-09 00:00:00-05:00      0.540207      0.213986      0.475901   \n",
       "...                                 ...           ...           ...   \n",
       "2017-09-25 00:00:00-04:00      0.000000      0.000000      0.000000   \n",
       "2017-09-26 00:00:00-04:00      0.000000      0.000000      0.000000   \n",
       "2017-09-27 00:00:00-04:00      0.000000      0.000000      0.000000   \n",
       "2017-09-28 00:00:00-04:00      0.000000      0.000000      0.000000   \n",
       "2017-09-29 00:00:00-04:00      0.000000      0.000000      0.000000   \n",
       "\n",
       "                           PG_2_h_omega  \n",
       "Date                                     \n",
       "2017-01-03 00:00:00-05:00      0.307302  \n",
       "2017-01-04 00:00:00-05:00      0.654365  \n",
       "2017-01-05 00:00:00-05:00      0.967940  \n",
       "2017-01-06 00:00:00-05:00      0.359668  \n",
       "2017-01-09 00:00:00-05:00      2.597965  \n",
       "...                                 ...  \n",
       "2017-09-25 00:00:00-04:00      0.000000  \n",
       "2017-09-26 00:00:00-04:00      0.000000  \n",
       "2017-09-27 00:00:00-04:00      0.000000  \n",
       "2017-09-28 00:00:00-04:00      0.000000  \n",
       "2017-09-29 00:00:00-04:00      0.000000  \n",
       "\n",
       "[188 rows x 4 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
